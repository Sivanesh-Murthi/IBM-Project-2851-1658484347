{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1unROm0ZJoy0FOsUm6v1CmGD4F95Dw7lt",
      "authorship_tag": "ABX9TyNWzenIcAxgUZkgRHSty7R5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sivanesh-Murthi/IBM-Project-2851-1658484347/blob/main/Project%20Development%20Phase/Sprint%204/Forest_Fire_Detection_Final_APP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qkEA-suzCWwY"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the parameters/arguments for ImageDataGenerator class\n",
        "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,rotation_range=180,zoom_range=0.2,horizontal_flip=True)\n",
        "\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "Ce1VmNyXESnF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying ImageDataGenerator functionality to testset\n",
        "x_test=test_datagen.flow_from_directory('/content/drive/MyDrive/Dataset/Dataset/test_set',target_size=(128,128),batch_size=32,class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UI561ZOgEV7k",
        "outputId": "282f7796-442b-4079-df53-53331540c452"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 121 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying ImageDataGenerator functionality to trainset\n",
        "x_train=train_datagen.flow_from_directory('/content/drive/MyDrive/Dataset/Dataset/train_set',target_size=(128,128),batch_size=32,class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHk1akcaEV2T",
        "outputId": "aefcd83a-4237-43d2-8f72-4d1f23c9d15a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 454 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import model building libraries\n",
        "#To define Linear initialisation import Sequential\n",
        "from keras.models import Sequential\n",
        "#To add layers import Dense\n",
        "from keras.layers import Dense\n",
        "#To create Convolution kernel import Convolution2D\n",
        "from keras.layers import Convolution2D\n",
        "#import Maxpooling layer\n",
        "from keras.layers import MaxPooling2D\n",
        "#import flatten layer\n",
        "from keras.layers import Flatten\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "148B546UFIBU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initializing the model\n",
        "model=Sequential()"
      ],
      "metadata": {
        "id": "Hlz5VbxRFMCL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#add convolutional layer\n",
        "model.add(Convolution2D(32,(3,3),input_shape=(128,128,3),activation='relu'))\n",
        "#add maxpooling layer\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#add flatten layer \n",
        "model.add(Flatten())"
      ],
      "metadata": {
        "id": "re5oR3U7FNvz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#add hidden layer\n",
        "model.add(Dense(150,activation='relu'))\n",
        "#add output layer\n",
        "model.add(Dense(1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "_k85CmI_FQ_2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#configure the learning process\n",
        "model.compile(loss='binary_crossentropy',optimizer=\"adam\",metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "Vlct_F0CFcV9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the model\n",
        "model.fit_generator(x_train,steps_per_epoch=14,epochs=10,validation_data=x_test,validation_steps=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyEmwtyNGCcb",
        "outputId": "9576f3c4-e9e4-4121-a41d-e603b2b04a7b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "14/14 [==============================] - 118s 8s/step - loss: 2.1155 - accuracy: 0.7180 - val_loss: 0.1380 - val_accuracy: 0.9669\n",
            "Epoch 2/10\n",
            "14/14 [==============================] - 27s 2s/step - loss: 0.3859 - accuracy: 0.8910 - val_loss: 0.1455 - val_accuracy: 0.9504\n",
            "Epoch 3/10\n",
            "14/14 [==============================] - 27s 2s/step - loss: 0.3946 - accuracy: 0.8768 - val_loss: 0.2072 - val_accuracy: 0.9504\n",
            "Epoch 4/10\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.3493 - accuracy: 0.8957 - val_loss: 0.1262 - val_accuracy: 0.9504\n",
            "Epoch 5/10\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.3119 - accuracy: 0.8626 - val_loss: 0.1760 - val_accuracy: 0.9174\n",
            "Epoch 6/10\n",
            "14/14 [==============================] - 27s 2s/step - loss: 0.2713 - accuracy: 0.8839 - val_loss: 0.1608 - val_accuracy: 0.9174\n",
            "Epoch 7/10\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.1896 - accuracy: 0.9336 - val_loss: 0.0827 - val_accuracy: 0.9669\n",
            "Epoch 8/10\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.1512 - accuracy: 0.9408 - val_loss: 0.0829 - val_accuracy: 0.9835\n",
            "Epoch 9/10\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.1398 - accuracy: 0.9408 - val_loss: 0.1616 - val_accuracy: 0.9504\n",
            "Epoch 10/10\n",
            "14/14 [==============================] - 27s 2s/step - loss: 0.1734 - accuracy: 0.9289 - val_loss: 0.1682 - val_accuracy: 0.9504\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff091afb5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install opencv-python\n",
        "!pip install opencv-contrib-python\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import cv2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce_j0EmdTWZD",
        "outputId": "07e716bc-5e03-4963-dde8-1df2e658226e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.9.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.27.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.50.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.14.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.6.0.66)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (4.6.0.66)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-contrib-python) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_test)\n",
        "predictions = np.round(predictions)\n",
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbdTOJ_uQEhz",
        "outputId": "81325b29-ebbc-4a1d-d86d-9fbe1a1a3523"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 5s 1s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9Jl9w7eUQnZ",
        "outputId": "bcb019fe-ad9e-4371-8d8d-5d91728604c2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/forest1.h5\")"
      ],
      "metadata": {
        "id": "Jmlqb-qwQRv6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import load_model from keras.model\n",
        "from keras.models import load_model\n",
        "#import image class from keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "#import numpy\n",
        "import numpy as np\n",
        "#import cv2\n",
        "import cv2"
      ],
      "metadata": {
        "id": "HVjXpLinT-sT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(\"/content/drive/MyDrive/forest1.h5\")"
      ],
      "metadata": {
        "id": "D6lgqqY7T5cG"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predictImage(filename):\n",
        "  img1 = image.load_img(filename,target_size=(128,128))\n",
        "  Y = image.img_to_array(img1)\n",
        "  X = np.expand_dims(Y,axis=0)\n",
        "  val = model.predict(X)\n",
        "  print(val)\n",
        "  if val == 1:\n",
        "    print(\" fire\")\n",
        "  elif val == 0:\n",
        "      print(\"no fire\")"
      ],
      "metadata": {
        "id": "yN9yemiXUYCQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictImage(\"/content/drive/MyDrive/Dataset/Dataset/test_set/with fire/19464620_401.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7FMFCvNUB8g",
        "outputId": "41e3c151-7043-4d64-b4ca-854c3e4fc980"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 82ms/step\n",
            "[[1.]]\n",
            " fire\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install twilio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkhsXwxcUdyA",
        "outputId": "6d58d9ab-40c8-4f7c-ee5a-7242ac7d4b14"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting twilio\n",
            "  Downloading twilio-7.15.3-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 6.9 MB/s \n",
            "\u001b[?25hCollecting PyJWT<3.0.0,>=2.0.0\n",
            "  Downloading PyJWT-2.6.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from twilio) (2022.6)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from twilio) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->twilio) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->twilio) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->twilio) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->twilio) (3.0.4)\n",
            "Installing collected packages: PyJWT, twilio\n",
            "Successfully installed PyJWT-2.6.0 twilio-7.15.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install playsound"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76gvG5FQUgoU",
        "outputId": "f5342397-73cc-4a17-b48c-edeb5ee69221"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting playsound\n",
            "  Downloading playsound-1.3.0.tar.gz (7.7 kB)\n",
            "Building wheels for collected packages: playsound\n",
            "  Building wheel for playsound (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for playsound: filename=playsound-1.3.0-py3-none-any.whl size=7035 sha256=fbe8e82f94b9628f8fb70a939affee5f753beabc947563c85fc29a1a896c44c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/f8/bb/ea57c0146b664dca3a0ada4199b0ecb5f9dfcb7b7e22b65ba2\n",
            "Successfully built playsound\n",
            "Installing collected packages: playsound\n",
            "Successfully installed playsound-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pygobject"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApSUQjzggHzf",
        "outputId": "621fc455-efea-49ca-9a21-44f839e68e11"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pygobject in /usr/lib/python3/dist-packages (3.26.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import opencv librariy\n",
        "import cv2\n",
        "#import numpy\n",
        "import numpy as np\n",
        "#import image function from keras\n",
        "from keras.preprocessing import image\n",
        "#import load_model from keras\n",
        "from keras.models import load_model\n",
        "#import client from twilio API\n",
        "from twilio.rest import Client\n",
        "#imort playsound package\n",
        "from playsound import playsound"
      ],
      "metadata": {
        "id": "OoicRjcTUsgs"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the saved model\n",
        "model = load_model(r'/content/drive/MyDrive/forest1.h5')\n",
        "#define video\n",
        "video = cv2.VideoCapture('/content/Fighting Fire with Fire _ Explained in 30 Seconds.mp4')\n",
        "#define the features\n",
        "name = ['forest','with forest']"
      ],
      "metadata": {
        "id": "JY2JTd1nUtcO"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "account_sid = 'AC6981743c2fda3548359b3cba6459b343'\n",
        "auth_token = '07335faf2a5a6aa032080639bd3f4190'\n",
        "client = Client(account_sid, auth_token)\n",
        "message=client.messages \\\n",
        "       .create(\n",
        "       body='Stay Alert!!! Forest Fire is Detected...',\n",
        "       from_='+18312734662',to='+917373083830')\n",
        "       \n",
        "print(message.sid)\n",
        "print('Fire Detected')\n",
        "print('SMS sent')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0bUvXg6VFdz",
        "outputId": "a78f8680-14c1-480b-bf72-fd747d4f7e44"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SMb739dd8886ed27263d3e7c15f10a5e42\n",
            "Fire Detected\n",
            "SMS sent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#import opencv library\n",
        "import cv2\n",
        "#import numpy\n",
        "import numpy as np\n",
        "#import image function from keras\n",
        "from keras.preprocessing import image\n",
        "#import load_model from keras\n",
        "from keras.models import load_model\n",
        "#import client from twilio API\n",
        "from twilio.rest import Client\n",
        "#imort playsound package\n",
        "from playsound import playsound\n",
        "\n",
        "#load the saved model\n",
        "model = load_model(\"/content/drive/MyDrive/Dataset/forest1.h5\")\n",
        "#define video\n",
        "video = cv2.VideoCapture(0)\n",
        "#define the features\n",
        "name = ['forest','with forest']\n",
        "\n",
        "account_sid = 'AC6981743c2fda3548359b3cba6459b343'\n",
        "auth_token = '07335faf2a5a6aa032080639bd3f4190'\n",
        "client = Client(account_sid, auth_token)\n",
        "\n",
        "message = client.messages \\\n",
        "    .create(\n",
        "         body='Stay Alert!!! Forest Fire is Detected...',\n",
        "         from_='+18312734662',\n",
        "         to='+917373083830'\n",
        "     )\n",
        "\n",
        "print(message.sid)\n",
        "\n",
        "#import opencv library\n",
        "import cv2\n",
        "#import numpy\n",
        "import numpy as np\n",
        "#import images and load_model function from keras\n",
        "from keras_preprocessing import image\n",
        "from keras.models import load_model\n",
        "#import client from twilio API\n",
        "from  twilio.rest import Client\n",
        "#import playsound package\n",
        "from playsound import playsound\n",
        "\n",
        "#load the saved model\n",
        "model = load_model(\"/content/drive/MyDrive/Dataset/forest1.h5\")\n",
        "video = cv2.VideoCapture(0)\n",
        "name = ['forest','with fire']\n",
        "if video.isOpened():\n",
        "  currentFrame=0\n",
        "  while(True):\n",
        "          success, frame=video.read()\n",
        "          cv2.imwrite(\"image.jpg\",frame)\n",
        "          img=image.load_img(\"image.jpg\",target_size=(128,128,3))\n",
        "          x=image.img_to_array(img)\n",
        "          x=np.expand_dims(x,axis=0)\n",
        "          pred=model.predict(x)\n",
        "          p=pred[0]\n",
        "          print(pred)\n",
        "          pred=model.predict(x)\n",
        "  \n",
        "          if pred[0]==1:    \n",
        "              account_sid = 'AC6981743c2fda3548359b3cba6459b343'\n",
        "              auth_token = '07335faf2a5a6aa032080639bd3f4190'\n",
        "              client = Client(account_sid, auth_token)\n",
        "              message=client.messages \\\n",
        "              .create(\n",
        "              body='Stay Alert!!! Forest Fire is Detected...',\n",
        "              from_='+18312734662',to='+917373083830')\n",
        "       \n",
        "              print(message.sid)\n",
        "              print('Fire Detected')\n",
        "              print('SMS sent')\n",
        "              playsound(r'\"/content/drive/MyDrive/Dataset/alarm_buzzer.mp3\"')\n",
        "       \n",
        "          else:\n",
        "             print(\"No Danger\")  \n",
        "        \n",
        "             cv2.imshow(\"image\",frame)  \n",
        "        \n",
        "          if cv2.waitKey(1) & 0xFF ==ord('a'):\n",
        "             break\n",
        "          currentFrame +=1\n",
        "video.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAMSl9vHk1H-",
        "outputId": "cce41eed-7e81-4469-9fc6-e024583d3abc"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SM08e7c9dcec9f258206fc22fcf376eac6\n"
          ]
        }
      ]
    }
  ]
}